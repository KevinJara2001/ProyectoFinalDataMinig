
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.tree import DecisionTreeRegressor, plot_tree
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, KFold, GridSearchCV
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler

st.set_page_config(layout="wide")
st.title("üìä Dashboard de Predicci√≥n de Demanda Notarial")


# -*- coding: utf-8 -*-
"""Proyecto_Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UkahlsK11WXuurtrKMC03oo28s1vWahD
"""

import numpy as np
import pandas as pd
import seaborn as sns
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor, plot_tree
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.model_selection import train_test_split, GridSearchCV, KFold
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error,  mean_absolute_error, r2_score

# Carga del CSV, se lo debe subir en el menu lateral de la izquierda en Archivos (icono de carpeta)
df = pd.read_csv("/content/dataset_servicios_generado_demanda.csv")
# Seleccion solo columnas num√©ricas
df_num = df.select_dtypes(include=[np.number])

cat_cols = [
    col for col in df.select_dtypes(include=['object', 'category']).columns
    if col not in ['fecha', 'hora']
]

# Muestra solo los valores unicos
for col in cat_cols:
    print(f"Valores √∫nicos en {col}:")
    print(df[col].unique())

# muestra Estad√≠sticos descriptivos
print(df_num.describe())
# y tipos de datos
print(df.dtypes)

# Histogramas
df_num.hist(figsize=(8, 6))
plt.tight_layout()
plt.show()

# Pairplot s√≥lo con num√©ricas
sns.pairplot(df_num)
plt.show()

# Matriz de correlaciones
plt.figure(figsize=(10, 8))
sns.heatmap(df_num.corr(), annot=True, fmt=".2f", cmap="coolwarm")
plt.title("Heatmap de la matriz de correlaci√≥n")
plt.show()

# Boxplots horizontales para detectar outliers
plt.figure(figsize=(10, 6))
df_num.boxplot(vert=False)
plt.title("Boxplots horizontales para detecci√≥n de outliers o valores at√≠picos")
plt.xlabel("Valor")
plt.ylabel("Variables")
plt.tight_layout()
plt.show()

display(df.head()) #muestra las 5 primeras filas


# ====================
# Secci√≥n de carga interactiva
# ====================

st.sidebar.header("üìÇ Opciones del Dashboard")

# Selector de dataset
dataset_opcion = st.sidebar.selectbox(
    "Selecciona el conjunto de datos:",
    ("Original", "Normalizado")
)

# Cargar dataset seg√∫n opci√≥n
if dataset_opcion == "Original":
    df = pd.read_csv("dataset_servicios_generado_demanda.csv")
else:
    df = pd.read_csv("dataset_servicios_normalizado.csv")

st.sidebar.markdown("---")

# Filtro por a√±o
if 'fecha' in df.columns:
    df['fecha_dt'] = pd.to_datetime(df['fecha'])
    df['a√±o'] = df['fecha_dt'].dt.year

    a√±os_disponibles = df['a√±o'].dropna().unique()
    a√±o_seleccionado = st.sidebar.selectbox("Filtrar por a√±o:", sorted(a√±os_disponibles))

    df = df[df['a√±o'] == a√±o_seleccionado]

st.sidebar.markdown("---")

# Filtro por tipo de servicio
if 'tipo_servicio' in df.columns:
    tipos = df['tipo_servicio'].dropna().unique().tolist()
    tipo_seleccionado = st.sidebar.multiselect("Filtrar por tipo de servicio:", tipos, default=tipos)
    df = df[df['tipo_servicio'].isin(tipo_seleccionado)]


"""# **LIMPIEZA DE DATOS**"""

# reemplaza NaN por 0, en demanda diaria
df['demanda_diaria'] = df['demanda_diaria'].fillna(0)
df_num = df.select_dtypes(include=[np.number])

# reemplaza NaN por 0, en tiempo_servicio_min
df['tiempo_servicio_min'] = df['tiempo_servicio_min'].fillna(0)
df_num = df.select_dtypes(include=[np.number])

# reemplaza NaN por 0, en usuarios_diarios
df['usuarios_diarios'] = df['usuarios_diarios'].fillna(0)
df_num = df.select_dtypes(include=[np.number])

# reemplaza NaN por 0, en capacidad_maxima_diaria
df['capacidad_maxima_diaria'] = df['capacidad_maxima_diaria'].fillna(0)
df_num = df.select_dtypes(include=[np.number])

# reemplaza NaN por ninguno, en tipo_servicio
df['tipo_servicio'] = df['tipo_servicio'].fillna("ninguno")
df_num = df.select_dtypes(include=[np.number])

# cambiamos los valores NaN de hora por 00:00 de forma que el modelo lo reconozca como "sin hora valida"
# Convierte y extrae solo la hora
# 1) Imputa los NaN en 'hora' con "00:00"

# 1) Rellena los NaN de 'hora' con "00:00"
df['hora'] = df['hora'].fillna('00:00')

# 2) Convierte directamente a datetime64
df['hora_dt'] = pd.to_datetime(
    df['hora'],
    format='%H:%M',
    errors='coerce'
)

# 3) Verifica que ahora sea datetime y muestra las primeras filas
print("Tipo de dato de hora_dt:", df['hora_dt'].dtype)
df['hora_dt'].head()

# reemplaza NaN por la media, en costo_servicio
mean_costo_servicio = df['costo_servicio'].mean()
df['costo_servicio'] = df['costo_servicio'].fillna(mean_costo_servicio)
df_num = df.select_dtypes(include=[np.number])

# transformar fecha tipo string a tipo datatime para un mejor manejo
df['fecha_dt'] = pd.to_datetime(df['fecha'])

# Fecha ‚Üí un entero ordinal (d√≠as desde 01-01-0001)
df['fecha_ordinal'] = df['fecha_dt'].map(pd.Timestamp.toordinal)


# Hora ‚Üí minutos desde medianoche
df['hora_minutos'] = df['hora_dt'].dt.hour * 60 + df['hora_dt'].dt.minute

# transformar columna dias_semana en tipo n√∫merico
dias_map = {
    'Lunes': 0,
    'Martes': 1,
    'Mi√©rcoles': 2,
    'Jueves': 3,
    'Viernes': 4,
    'S√°bado': 5,
}

df['dia_semana_num'] = df['dia_semana'].map(dias_map)

# transformar columna "tipo" en tipo n√∫merico
tipo_map = {
    'feriado': 0,
    'servicio': 1,
    'ausencia': 2,
    'permiso': 3,
    'vacaciones': 4,
}

df['tipo_num'] = df['tipo'].map(tipo_map)

# transformar columna "tipo_servicio" en tipo n√∫merico
# 'ninguno' 'Actos y Contratos con Cuant√≠a Determinada' 'Declaratoria de Propiedad Horizontal''Poderes, Procuraciones Judiciales y Contratos de Mandato''De las Sociedades''Actos Contratos y Diligencias Notariales con Tarifas Especiales''Remates Voluntarios'
# 'Actos Contratos y Dilgencia con Cuant√≠a Indeterminada'
tipo_servicio_map = {
    'ninguno': 0,
    'Actos y Contratos con Cuant√≠a Determinada': 1,
    'Declaratoria de Propiedad Horizontal': 2,
    'Poderes, Procuraciones Judiciales y Contratos de Mandato': 3,
    'De las Sociedades': 4,
    'Actos Contratos y Diligencias Notariales con Tarifas Especiales': 5,
    'Remates Voluntarios': 6,
    'Actos Contratos y Dilgencia con Cuant√≠a Indeterminada': 7,
}

df['tipo_servicio_num'] = df['tipo_servicio'].map(tipo_servicio_map)

cat_cols = [
    col for col in df.select_dtypes(include=['object', 'category']).columns
    if col not in ['fecha', 'hora']
]

# Muestra solo los valores unicos
for col in cat_cols:
    print(f"Valores √∫nicos en {col}:")
    print(df[col].unique())

df['a√±o']  = df['fecha_dt'].dt.year
df['mes']  = df['fecha_dt'].dt.month

# Agrupa por a√±o y mes y calcula, por ejemplo, la suma de demanda diaria
resumen = (
    df
    .groupby(['a√±o','mes'])['demanda_diaria']
    .sum()
    .reset_index()
    .sort_values(['a√±o','mes'])
)

"""# **ENTRENAMIENTO Random Forest Regressor**"""

# Separar variables predictoras (X) y variable objetivo (y)
# Excluye columnas no num√©ricas y la variable objetivo
X = df.select_dtypes(exclude=['object', "datetime64[ns]"])
X = X.drop(columns=['demanda_diaria'])
y = df["demanda_diaria"]

# se muestra el numero de filas y columnas
print("Filas y columnas de X:", X.shape)
print("Filas de Y:", y.shape[0])

X.dtypes

# Se divide en entrenamiento y prueba train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Configuraci√≥n y Entrenamiento del modelo
# n_estimators -> representa todos los √°rboles que utiliza para entrenar el modelo
#n_jobs = -1 -> se asegura de que utilice todos los n√∫cleos para acelerar el entrenamiento
rfr = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)
rfr.fit(X_train, y_train)

# Predecir sobre conjunto de prueba
y_pred = rfr.predict(X_test)

# Evaluar el modelo
mae_rfr = mean_absolute_error(y_test, y_pred)
mse_rfr = mean_squared_error(y_test, y_pred)
rmse_rfr = np.sqrt(mse_rfr)
r2_rfr = r2_score(y_test, y_pred)

mae_rfr, rmse_rfr, r2_rfr
print(f"MAE: {mae_rfr:.6f}")
print(f"MSE: {mse_rfr:.6f}")
print(f"RMSE: {rmse_rfr:.6f}")
print(f"R¬≤: {r2_rfr:.6f}")

"""# **Validacion Cruzada con Random Forest Regressor**"""

# Configura el modelo con menos √°rboles y sin paralelismo excesivo
rf_model = RandomForestRegressor(
    n_estimators=50,       # reduce para acelerar
    max_depth=10,
    random_state=42,
    n_jobs=-1               # evita saturar entorno
)

# K-Fold con menos particiones, 5 para m√°s velocidad
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# Almacena m√©tricas
mae_scores = []
mse_scores = []

# Validaci√≥n cruzada manual
for train_idx, val_idx in kf.split(X):
    X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]
    y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]

    rf_model.fit(X_train_fold, y_train_fold)
    y_pred_fold = rf_model.predict(X_val_fold)

    mae_scores.append(mean_absolute_error(y_val_fold, y_pred_fold))
    mse_scores.append(mean_squared_error(y_val_fold, y_pred_fold))

# Resultados promedio y desviaci√≥n
avg_mae = np.mean(mae_scores)
std_mae = np.std(mae_scores)
avg_mse = np.mean(mse_scores)
std_mse = np.std(mse_scores)

print(f"MAE promedio y desviaci√≥n est√°ndar: {avg_mae:.6f} ¬± {std_mae:.6f}")
print(f"MSE promedio y desviaci√≥n est√°ndar: {avg_mse:.6f} ¬± {std_mse:.6f}")

# Visualizar los errores por fold
plt.plot(mae_scores, marker='o', label='MAE por fold')
plt.plot(mse_scores, marker='s', label='MSE por fold')
plt.title("Errores por conjunto de datos de validaci√≥n - RandomForestRegressor")
plt.xlabel("Conjunto de datos de validaci√≥n")
plt.ylabel("Error")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""**Gr√°fica para comparar prediccion y datos reales**"""

# Si conoces la media y desviaci√≥n original de 'demanda_diaria':
media_original = df['demanda_diaria'].mean()     # obtiene el media real
std_original = df['demanda_diaria'].std()       # obtiene por el desviaci√≥n est√°ndar real

# Desnormalizar
y_test_real = y_test * std_original + media_original
y_pred_real = y_pred * std_original + media_original

# Graficar desnormalizado
plt.figure(figsize=(6, 6))
plt.scatter(y_test_real, y_pred_real, alpha=0.6, color='green')
plt.plot([y_test_real.min(), y_test_real.max()], [y_test_real.min(), y_test_real.max()], 'r--', linewidth=2)
plt.xlabel("Demanda real")
plt.ylabel("Demanda predicha")
plt.title("Predicci√≥n vs Valor Real")
plt.grid(True)
plt.tight_layout()
plt.show()

errores = y_test - y_pred

# Histograma de errores
plt.hist(errores, bins=30, edgecolor='black')
plt.title("Distribuci√≥n de errores")
plt.xlabel("Error")
plt.ylabel("Frecuencia")
plt.grid(True)
plt.show()

# Errores vs predicci√≥n
plt.scatter(y_pred, errores, alpha=0.5, edgecolor='k')
plt.axhline(0, color='red', linestyle='--')
plt.title("Errores vs Predicci√≥n")
plt.xlabel("Predicci√≥n")
plt.ylabel("Error")
plt.grid(True)
plt.show()

"""# **ENTRENAMIENTO Arboles de decisi√≥n**"""

# Definir el modelo base con par√°metros razonables
dt = DecisionTreeRegressor(
    random_state=42,
    max_depth=5,               # Profundidad controlada
    min_samples_split=5,       # Evita divisiones excesivas
    min_samples_leaf=2         # Hojas con m√≠nimo 2 muestras
)

# Entrenamiento
dt.fit(X_train, y_train)

# Predicci√≥n y m√©tricas
y_pred = dt.predict(X_test)
mse_dt = mean_squared_error(y_test, y_pred)
mae_dt = mean_absolute_error(y_test, y_pred)
rmse_dt = np.sqrt(mse_dt)
r2_dt  = r2_score(y_test, y_pred)

print(f"MAE: {mae_dt:.6f}")
print(f"MSE: {mse_dt:.6f}")
print(f"RMSE:{rmse_dt:.6f}")
print(f"R¬≤:  {r2_dt:.6f}")

# Visualizaci√≥n del √°rbol (primeros 3 niveles)
plt.figure(figsize=(16, 10))
plot_tree(
    dt,
    feature_names=X.columns,
    filled=True,
    rounded=True,
    max_depth=3,
    fontsize=10
)
plt.title("√Årbol de Decisi√≥n (Visualizaci√≥n hasta nivel 3)")
plt.show()

# B√∫squeda de mejores hiperpar√°metros con GridSearchCV
param_grid = {
    'max_depth': [3, 5, 10, 15],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

grid_dt = GridSearchCV(
    estimator=DecisionTreeRegressor(random_state=42),
    param_grid=param_grid,
    scoring='neg_mean_absolute_error',  # tambi√©n podr√≠as usar 'r2' o 'neg_mean_squared_error'
    cv=5,
    verbose=1
)
# entrenamiento
grid_dt.fit(X_train, y_train)

# Resultados de la b√∫squeda
print("Mejores par√°metros encontrados:", grid_dt.best_params_)
print("Mejor MAE en validaci√≥n cruzada:", -grid_dt.best_score_)

"""# **Validacion Cruzada con Arboles de decisi√≥n**"""

# Definir el modelo
dt_model = DecisionTreeRegressor(
    random_state=42,
    max_depth=5,
    min_samples_split=2,  # ajustar si es necesario
    min_samples_leaf=1
)

# K-Fold configuration, 5 subconjuntos de datos de validaci√≥n
kf = KFold(n_splits=5, shuffle=True, random_state=42)

# Almacenar m√©tricas
mae_scores = []
mse_scores = []

# Validaci√≥n cruzada
for train_idx, val_idx in kf.split(X):
    X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]
    y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]

    dt_model.fit(X_train_fold, y_train_fold)
    y_pred_fold = dt_model.predict(X_val_fold)

    mae_scores.append(mean_absolute_error(y_val_fold, y_pred_fold))
    mse_scores.append(mean_squared_error(y_val_fold, y_pred_fold))

# Resultados agregados
avg_mae = np.mean(mae_scores)
std_mae = np.std(mae_scores)
avg_mse = np.mean(mse_scores)
std_mse = np.std(mse_scores)

print(f"MAE promedio y desviacion estandar: {avg_mae:.6f} ¬± {std_mae:.6f}")
print(f"MSE promedio y desviacion estandar: {avg_mse:.6f} ¬± {std_mse:.6f}")

# Visualizaci√≥n de errores por fold
plt.plot(mae_scores, marker='o', label='MAE por fold')
plt.plot(mse_scores, marker='s', label='MSE por fold')
plt.title("Errores por subconjuntos de datos de validaci√≥n - √Årbol de Decisi√≥n (max_depth=5)")
plt.xlabel("Fold")
plt.ylabel("Error")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""**Gr√°fica para comparar prediccion y datos reales**"""

plt.figure(figsize=(6, 6))
plt.scatter(y_test, y_pred, alpha=0.6, color='blue', label="Predicciones")
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label="Perfecto")
plt.xlabel("Valor real")
plt.ylabel("Predicci√≥n")
plt.title("Predicci√≥n vs Valor Real - √Årbol de Decisi√≥n")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

errores = y_test - y_pred

# Histograma de errores
plt.hist(errores, bins=30, edgecolor='black')
plt.title("Distribuci√≥n de errores")
plt.xlabel("Error")
plt.ylabel("Frecuencia")
plt.grid(True)
plt.show()

# Errores vs predicci√≥n
plt.scatter(y_pred, errores, alpha=0.5, edgecolor='k')
plt.axhline(0, color='red', linestyle='--')
plt.title("Errores vs Predicci√≥n")
plt.xlabel("Predicci√≥n")
plt.ylabel("Error")
plt.grid(True)
plt.show()

"""# **Comparacion de modelos**"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Diccionario vac√≠o donde se ir√°n agregando resultados
resultados = []

# === EJEMPLO: Agrega resultados luego de entrenar cada modelo ===

# √Årbol de Decisi√≥n
resultados.append({
    "Modelo": "√Årbol de Decisi√≥n",
    "MAE": mae_dt,
    "RMSE": rmse_dt,
    "MSE": mse_dt,
    "R¬≤": r2_dt
})

# Random Forest
resultados.append({
    "Modelo": "Random Forest",
    "MAE": mae_rfr,
    "RMSE": rmse_rfr,
    "MSE": mse_rfr,
    "R¬≤": r2_rfr
})

# === CONVERTIR A DATAFRAME ===
df_resultados = pd.DataFrame(resultados)

# Mostrar tabla en consola
print("Comparaci√≥n de Modelos:")
print(df_resultados)

# === GRAFICAR COMPARACI√ìN ===
fig, axs = plt.subplots(2, 2, figsize=(12, 8))

# MAE
sns.barplot(x="Modelo", y="MAE", data=df_resultados, ax=axs[0, 0], palette="Blues")
axs[0, 0].set_title("MAE - Error Absoluto Medio")
axs[0, 0].set_ylabel("MAE")

# RMSE
sns.barplot(x="Modelo", y="RMSE", data=df_resultados, ax=axs[0, 1], palette="Greens")
axs[0, 1].set_title("RMSE - Ra√≠z del Error Cuadr√°tico Medio")
axs[0, 1].set_ylabel("RMSE")

# MSE
sns.barplot(x="Modelo", y="MSE", data=df_resultados, ax=axs[1, 0], palette="Oranges")
axs[1, 0].set_title("MSE - Error Cuadr√°tico Medio")
axs[1, 0].set_ylabel("MSE")

# R¬≤
sns.barplot(x="Modelo", y="R¬≤", data=df_resultados, ax=axs[1, 1], palette="Purples")
axs[1, 1].set_title("R¬≤ - Coeficiente de Determinaci√≥n")
axs[1, 1].set_ylabel("R¬≤")

plt.suptitle("Comparaci√≥n de Desempe√±o entre Modelos", fontsize=16)
plt.tight_layout()
plt.show()

"""Guardar Dataset Normalizado"""

# Guardar las columnas antes de escalar
columnas = X.columns

# Escalar
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Concatenar escalados
X_scaled = np.concatenate((X_train_scaled, X_test_scaled), axis=0)

# Crear DataFrame con las columnas correctas
X_scaled_df = pd.DataFrame(X_scaled, columns=columnas)

# Guardar a CSV
X_scaled_df.to_csv("dataset_servicios_normalizado.csv", index=False)

"""## Predecir con el conjunto de prueba

Generar predicciones utilizando el modelo entrenado con los datos de prueba.

"""

# Generar predicciones para todo el dataset
y_pred_all = rfr.predict(X)

# A√±adir predicciones al DataFrame original
df['demanda_predicha'] = y_pred_all

df['mes'] = df['fecha_dt'].dt.month

# Agrupar por mes
por_mes = df.groupby('mes')[['demanda_diaria', 'demanda_predicha']].sum().reset_index()

# Visualizar
por_mes.plot(x='mes', kind='bar', figsize=(10,5), title='Demanda Real vs Predicha por Mes')
plt.ylabel('Demanda total')
plt.xticks(rotation=0)
plt.grid(True)
plt.tight_layout()
plt.show()

# D√≠a de la semana ya num√©rico como 'dia_semana_num'
por_dia = df.groupby('dia_semana_num')[['demanda_diaria', 'demanda_predicha']].sum().reset_index()

# Mapear n√∫mero a nombre
dias = ['Lunes', 'Martes', 'Mi√©rcoles', 'Jueves', 'Viernes', 'S√°bado']
por_dia['dia'] = por_dia['dia_semana_num'].map(dict(zip(range(6), dias)))

# Visualizar
por_dia.plot(x='dia', kind='bar', figsize=(10,5), title='Demanda Real vs Predicha por D√≠a de la Semana')
plt.ylabel('Demanda total')
plt.xticks(rotation=0)
plt.grid(True)
plt.tight_layout()
plt.show()

"""## Agregar predicciones por mes y a√±o

### Subtarea:
Agrupar los datos combinados por mes y a√±o y calcular la demanda promedio prevista para cada mes.

**Razonamiento**:
Agrupar los datos combinados por a√±o y mes y calcular la demanda promedio prevista para cada mes.
"""

# Agrupaci√≥n
df_mensual = (
    df.groupby(['a√±o', 'mes'])[['demanda_diaria', 'demanda_predicha']]
    .mean()
    .reset_index()
    .sort_values(['a√±o', 'mes'])
)

# Mostrar tabla
print(df_mensual)

# Gr√°fico de l√≠neas
plt.figure(figsize=(12,6))
for a√±o in df_mensual['a√±o'].unique():
    datos_a√±o = df_mensual[df_mensual['a√±o'] == a√±o]
    plt.plot(datos_a√±o['mes'], datos_a√±o['demanda_diaria'], label=f'Real {a√±o}', marker='o')
    plt.plot(datos_a√±o['mes'], datos_a√±o['demanda_predicha'], label=f'Predicha {a√±o}', marker='x')

plt.title('Demanda Promedio Real vs Predicha por Mes y A√±o')
plt.xlabel('Mes')
plt.ylabel('Demanda Promedio')
plt.xticks(range(1,13))
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.show()

"""## Agregar predicciones por d√≠a de la semana

Agrupar los datos combinados por d√≠a de la semana y calcular la demanda promedio prevista para cada d√≠a.
"""

# Asegura que la columna 'dia_semana' exista
if 'dia_semana' not in df.columns:
    df['dia_semana'] = df['fecha_dt'].dt.day_name(locale='es_ES')

# Calcula el promedio de demanda predicha por d√≠a de la semana
daily_predictions = (
    df.groupby('dia_semana')[['demanda_predicha']]
    .mean()
    .reset_index()
    .rename(columns={'demanda_predicha': 'demanda_promedio_predicha'})
)

# Ordena los d√≠as correctamente
orden_dias = ['Lunes', 'Martes', 'Mi√©rcoles', 'Jueves', 'Viernes', 'S√°bado']
daily_predictions['dia_semana'] = pd.Categorical(
    daily_predictions['dia_semana'],
    categories=orden_dias,
    ordered=True
)
daily_predictions = daily_predictions.sort_values('dia_semana')

# Muestra resultados en tabla
print(daily_predictions)

plt.figure(figsize=(8, 5))
sns.barplot(
    data=daily_predictions,
    x='dia_semana',
    y='demanda_promedio_predicha',
    palette='viridis'
)
plt.title("Demanda Promedio Predicha por D√≠a de la Semana", fontsize=14)
plt.ylabel("Demanda Promedio Predicha", fontsize=12)
plt.xlabel("D√≠a de la Semana", fontsize=12)
plt.xticks(rotation=45)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()

"""## Visualizar predicciones mensuales

Crea gr√°fico lineal que muestre la demanda promedio mensual prevista a lo largo del tiempo.
"""

# Agrupar y calcular la demanda promedio predicha
monthly_predictions = (
    df.groupby(['a√±o', 'mes'])['demanda_predicha']
    .mean()
    .reset_index()
    .rename(columns={'demanda_predicha': 'demanda_promedio_predicha'})
)

# Crear columna de fecha real desde columnas 'a√±o' y 'mes'
monthly_predictions['fecha'] = pd.to_datetime({
    'year': monthly_predictions['a√±o'],
    'month': monthly_predictions['mes'],
    'day': 1  # D√≠a por defecto para representar el mes
})

"""Esta visualizaci√≥n sirve para evaluar tendencias y estacionalidad:"""

plt.figure(figsize=(10, 5))
sns.lineplot(data=monthly_predictions, x='fecha', y='demanda_promedio_predicha', marker='o', color='tab:blue')
plt.title('Demanda Promedio Predicha por Mes')
plt.xlabel('Fecha')
plt.ylabel('Demanda Promedio Predicha')
plt.grid(True)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""## Calcular la demanda promedio real por mes

"""

# Asegura de que las columnas 'fecha_dt', 'a√±o' y 'mes' existen
if 'fecha_dt' not in df.columns:
    df['fecha_dt'] = pd.to_datetime(df['fecha'])
df['a√±o'] = df['fecha_dt'].dt.year
df['mes'] = df['fecha_dt'].dt.month

# Agrupar por a√±o y mes, calcular demanda promedio real
monthly_real = (
    df.groupby(['a√±o', 'mes'])['demanda_diaria']
    .mean()
    .reset_index()
    .rename(columns={'demanda_diaria': 'demanda_promedio_real'})
)

# Crear columna fecha (primer d√≠a del mes) para eje X del gr√°fico
monthly_real['fecha'] = pd.to_datetime({
    'year': monthly_real['a√±o'],
    'month': monthly_real['mes'],
    'day': 1
})

# 4. Visualizaci√≥n: Gr√°fico de l√≠nea de la demanda mensual promedio
plt.figure(figsize=(10, 5))
sns.lineplot(
    data=monthly_real,
    x='fecha',
    y='demanda_promedio_real',
    marker='o',
    linewidth=2,
    color='teal'
)
plt.title("Demanda Promedio Real por Mes", fontsize=14)
plt.xlabel("Mes")
plt.ylabel("Demanda Promedio")
plt.grid(True, linestyle='--', alpha=0.6)
plt.tight_layout()
plt.show()

"""## Calcular la demanda promedio por a√±o"""

# Aseg√∫rate de tener la columna 'a√±o' extra√≠da de la fecha
if 'a√±o' not in df.columns:
    df['a√±o'] = df['fecha_dt'].dt.year

# Agrupar por a√±o y calcular la demanda promedio
yearly_avg = (
    df.groupby('a√±o')['demanda_diaria']
    .mean()
    .reset_index()
    .rename(columns={'demanda_diaria': 'demanda_promedio_anual'})
)

plt.figure(figsize=(8, 5))
sns.barplot(data=yearly_avg, x='a√±o', y='demanda_promedio_anual', palette='crest')
plt.title("Demanda Promedio Anual")
plt.xlabel("A√±o")
plt.ylabel("Demanda Promedio")
plt.grid(axis='y', linestyle='--', alpha=0.6)
plt.tight_layout()
plt.show()

"""# **Servicios mas utilizados por mes**"""

# Filtrar filas v√°lidas
df_filtrado = df.dropna(subset=['tipo_servicio', 'demanda_diaria'])

# Usa la columna ya convertida 'fecha_dt'
df_filtrado['mes'] = df_filtrado['fecha_dt'].dt.month_name()

# Agrupar por mes y tipo de servicio, sumando demanda
agrupado = df_filtrado.groupby(['mes', 'tipo_servicio'])['demanda_diaria'].sum().reset_index()

# Ordenar por demanda dentro de cada mes
agrupado_ordenado = agrupado.sort_values(['mes', 'demanda_diaria'], ascending=[True, False])

# Obtener servicio con m√°s demanda por mes
top_servicios_mes = agrupado_ordenado.groupby('mes').first().reset_index()

# Mostrar tabla
print("Servicios m√°s utilizados por mes:")
display(top_servicios_mes)

# Servicio m√°s utilizado del a√±o
servicio_top_anual = df_filtrado.groupby('tipo_servicio')['demanda_diaria'].sum().idxmax()
print(f"\nServicio m√°s utilizado en el a√±o 2024: {servicio_top_anual}")

import matplotlib.pyplot as plt
import seaborn as sns

# Mapeo de meses de ingl√©s a espa√±ol
meses_es = {
    "January": "Enero", "February": "Febrero", "March": "Marzo", "April": "Abril",
    "May": "Mayo", "June": "Junio", "July": "Julio", "August": "Agosto",
    "September": "Septiembre", "October": "Octubre", "November": "Noviembre", "December": "Diciembre"
}

# Aplicar mapeo
top_servicios_mes['mes_es'] = top_servicios_mes['mes'].map(meses_es)

# Orden cronol√≥gico
orden_meses_es = ["Enero", "Febrero", "Marzo", "Abril", "Mayo", "Junio",
                  "Julio", "Agosto", "Septiembre", "Octubre", "Noviembre", "Diciembre"]
top_servicios_mes['mes_es'] = pd.Categorical(top_servicios_mes['mes_es'], categories=orden_meses_es, ordered=True)
top_servicios_mes = top_servicios_mes.sort_values("mes_es")

# Gr√°fico de barras con meses
plt.figure(figsize=(12, 6))
sns.barplot(data=top_servicios_mes, x='mes_es', y='demanda_diaria', hue='tipo_servicio', dodge=False)
plt.title('Servicio m√°s demandado por mes')
plt.xlabel('Mes')
plt.ylabel('Demanda total')
plt.xticks(rotation=45)
plt.legend(title='Tipo de Servicio', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

"""# **Importancia de Variables**"""

# Imputar NaN restantes con la media (en variables num√©ricas) para evitar error
X = X.fillna(X.mean())

# Volver a ajustar y graficar
rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X, y)
importancias = rf.feature_importances_
features = X.columns

plt.figure(figsize=(10, 6))
sns.barplot(x=importancias, y=features)
plt.title("Importancia de Variables - Random Forest")
plt.xlabel("Importancia")
plt.ylabel("Caracter√≠sticas")
plt.tight_layout()
plt.grid(True)
plt.show()

"""# **Errores por fold (Validaci√≥n cruzada)**"""

# Validaci√≥n cruzada nuevamente
kf = KFold(n_splits=5, shuffle=True, random_state=42)
mae_scores = []
mse_scores = []

for train_idx, val_idx in kf.split(X):
    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

    rf.fit(X_train, y_train)
    y_pred = rf.predict(X_val)

    mae_scores.append(mean_absolute_error(y_val, y_pred))
    mse_scores.append(mean_squared_error(y_val, y_pred))

plt.figure(figsize=(10, 5))
plt.plot(mae_scores, marker='o', label='MAE por fold')
plt.plot(mse_scores, marker='s', label='MSE por fold')
plt.title("Errores por Fold - Validaci√≥n Cruzada")
plt.xlabel("Fold")
plt.ylabel("Error")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""# **Mapa de calor de correlaciones postprocesamiento**"""

# Mapa de correlaciones actualizado
corr = df.select_dtypes(include=[np.number]).corr()

plt.figure(figsize=(12, 10))
sns.heatmap(corr, annot=True, fmt=".2f", cmap="coolwarm", square=True)
plt.title("Mapa de Correlaciones (post procesamiento)")
plt.tight_layout()
plt.show()